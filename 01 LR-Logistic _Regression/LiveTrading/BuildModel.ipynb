{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mik/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from talib import abstract\n",
    "import yfinance as yf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"EURUSD=X\"\n",
    "interval ='5m'\n",
    "period = '60d'\n",
    "ptc = 0.00007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Build_LR_Model():\n",
    "    ''' Class creating a LogisticRegression model.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, symbol, interval, period, tc):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        symbol: str\n",
    "            ticker symbol (instrument) to be backtested\n",
    "        start: str\n",
    "            start date for data import\n",
    "        end: str\n",
    "            end date for data import\n",
    "        tc: float\n",
    "            proportional transaction/trading costs per trade\n",
    "        '''\n",
    "        self.symbol = symbol\n",
    "        self.tc = tc\n",
    "        self.model = LogisticRegression(C = 1e6, max_iter = 100000, multi_class = \"ovr\")\n",
    "        self.results = None\n",
    "        self.getHistoryYfinance(symbol, interval, period)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        rep = \"Build_LR_Model(symbol = {}, start = {}, end = {}, tc = {})\"\n",
    "        return rep.format(self.symbol, self.start, self.end, self.tc)\n",
    "\n",
    " \n",
    "    def getHistoryYfinance(self, symbol, interval, period):\n",
    "\n",
    "        data = yf.download(  # or pdr.get_data_yahoo(...\n",
    "        # tickers list or string as well\n",
    "        tickers = symbol,\n",
    "\n",
    "        # use \"period\" instead of start/end\n",
    "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "        # (optional, default is '1mo')\n",
    "        # period = \"ytd\",\n",
    "        period = period,\n",
    "\n",
    "        # fetch data by interval (including intraday if period < 60 days)\n",
    "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "        # (optional, default is '1d')\n",
    "        interval = interval,\n",
    "\n",
    "        # group by ticker (to access via data['SPY'])\n",
    "        # (optional, default is 'column')\n",
    "        group_by = 'ticker',\n",
    "\n",
    "        # adjust all OHLC automatically\n",
    "        # (optional, default is False)\n",
    "        auto_adjust = False,\n",
    "\n",
    "        # download pre/post regular market hours data\n",
    "        # (optional, default is False)\n",
    "        prepost = False,\n",
    "\n",
    "        # use threads for mass downloading? (True/False/Integer)\n",
    "        # (optional, default is True)\n",
    "        threads = True,\n",
    "\n",
    "        # proxy URL scheme use use when downloading?\n",
    "        # (optional, default is None)\n",
    "        proxy = None\n",
    "        )\n",
    "        \n",
    "        data.rename(columns={\"Close\": \"price\"}, inplace=True)\n",
    "        data[\"returns\"] = np.log(data['price'] / data['price'].shift(1))\n",
    "        data = data.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)\n",
    "        data.dropna(inplace=True)\n",
    "        self.data = data\n",
    "        self.start = min(data.index) \n",
    "        self.end = max(data.index) \n",
    "        \n",
    "        return data        \n",
    "        \n",
    "        \n",
    "        \n",
    "                                    \n",
    "    def split_data(self, start, end):\n",
    "        ''' Splits the data into training set & test set.\n",
    "        '''\n",
    "        data = self.data.loc[start:end].copy()\n",
    "        return data\n",
    "    \n",
    "    def prepare_features(self, start, end):\n",
    "        ''' Prepares the feature columns for training set and test set.\n",
    "        '''\n",
    "        self.data_subset = self.split_data(start, end)\n",
    "        self.feature_columns = []\n",
    "        for lag in range(1, self.lags + 1):\n",
    "            col = \"lag{}\".format(lag)\n",
    "            self.data_subset[col] = self.data_subset[\"returns\"].shift(lag)\n",
    "            self.feature_columns.append(col)\n",
    "            \n",
    "        self.data_subset['Ask_Dir'] = np.where(self.data_subset['price'].shift(-1) > self.data_subset.price, 1, 0)\n",
    "        self.feature_columns.append('Ask_Dir')\n",
    "\n",
    "        self.data_subset['SMA'] = abstract.SMA(self.data_subset['price'], timeperiod=12)\n",
    "        self.feature_columns.append('SMA')\n",
    "        self.data_subset['SMA_Dir'] = np.where(self.data_subset['SMA'].shift(-1) > self.data_subset.SMA, 1, 0)\n",
    "        self.feature_columns.append('SMA_Dir')\n",
    "\n",
    "        self.data_subset['RSI'] = abstract.RSI(self.data_subset['price'], timeperiod=12)\n",
    "        self.feature_columns.append('RSI')\n",
    "        self.data_subset['RSI_Dir'] = np.where(self.data_subset['RSI'].shift(-1) > self.data_subset.RSI, 1, 0)\n",
    "        self.feature_columns.append('RSI_Dir')\n",
    "        \n",
    "        self.data_subset['fastk'], self.data_subset['fastd'] = abstract.STOCHRSI(self.data_subset[\"price\"], timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "        self.feature_columns.append('fastk')\n",
    "        self.feature_columns.append('fastd')\n",
    "        self.data_subset['fastk_Dir'] = np.where(self.data_subset['fastk'].shift(-1) > self.data_subset.fastk, 1, 0)\n",
    "        self.feature_columns.append('fastk_Dir')\n",
    "        self.data_subset['fastd_Dir'] = np.where(self.data_subset['fastd'].shift(-1) > self.data_subset.fastd, 1, 0)    \n",
    "        self.feature_columns.append('fastd_Dir')\n",
    "            \n",
    "        self.data_subset.dropna(inplace=True)\n",
    "        \n",
    "    def fit_model(self, start, end):\n",
    "        ''' Fitting the ML Model.\n",
    "        '''\n",
    "        self.prepare_features(start, end)\n",
    "        self.model.fit(self.data_subset[self.feature_columns], np.sign(self.data_subset[\"returns\"]))\n",
    "        \n",
    "        \n",
    "    def test_strategy(self, train_ratio = 0.7, lags = 5):\n",
    "        ''' \n",
    "        Backtests the ML-based strategy.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        train_ratio: float (between 0 and 1.0 excl.)\n",
    "            Splitting the dataset into training set (train_ratio) and test set (1 - train_ratio).\n",
    "        lags: int\n",
    "            number of lags serving as model features.\n",
    "        '''\n",
    "        self.lags = lags\n",
    "                  \n",
    "        # determining datetime for start, end and split (for training an testing period)\n",
    "        full_data = self.data.copy()\n",
    "        split_index = int(len(full_data) * train_ratio)\n",
    "        split_date = full_data.index[split_index-1]\n",
    "        train_start = full_data.index[0]\n",
    "        test_end = full_data.index[-1]\n",
    "        \n",
    "        # fit the model on the training set\n",
    "        self.fit_model(train_start, split_date)\n",
    "        \n",
    "        # prepare the test set\n",
    "        self.prepare_features(split_date, test_end)\n",
    "                  \n",
    "        # make predictions on the test set\n",
    "        predict = self.model.predict(self.data_subset[self.feature_columns])\n",
    "        self.data_subset[\"pred\"] = predict\n",
    "        \n",
    "        # calculate Strategy Returns\n",
    "        self.data_subset[\"strategy\"] = self.data_subset[\"pred\"] * self.data_subset[\"returns\"]\n",
    "        \n",
    "        # determine the number of trades in each bar\n",
    "        self.data_subset[\"trades\"] = self.data_subset[\"pred\"].diff().fillna(0).abs()\n",
    "        \n",
    "        # subtract transaction/trading costs from pre-cost return\n",
    "        self.data_subset.strategy = self.data_subset.strategy - self.data_subset.trades * self.tc\n",
    "        \n",
    "        # calculate cumulative returns for strategy & buy and hold\n",
    "        self.data_subset[\"creturns\"] = self.data_subset[\"returns\"].cumsum().apply(np.exp)\n",
    "        self.data_subset[\"cstrategy\"] = self.data_subset['strategy'].cumsum().apply(np.exp)\n",
    "        self.results = self.data_subset\n",
    "        \n",
    "        perf = self.results[\"cstrategy\"].iloc[-1] # absolute performance of the strategy\n",
    "        outperf = perf - self.results[\"creturns\"].iloc[-1] # out-/underperformance of strategy\n",
    "        \n",
    "        return round(perf, 6), round(outperf, 6)\n",
    "    \n",
    "    def store_model(self):\n",
    "        pickle.dump(self.model, open(\"logreg.pkl\", \"wb\"))\n",
    "        print('The model has been stored.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ml = Build_LR_Model(symbol, interval, period ,ptc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ml.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-20 00:05:00+00:00</th>\n",
       "      <td>1.084011</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20 00:10:00+00:00</th>\n",
       "      <td>1.084246</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20 00:15:00+00:00</th>\n",
       "      <td>1.084246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20 00:20:00+00:00</th>\n",
       "      <td>1.084246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20 00:25:00+00:00</th>\n",
       "      <td>1.084011</td>\n",
       "      <td>-0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-13 15:35:00+01:00</th>\n",
       "      <td>1.105217</td>\n",
       "      <td>-0.000774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-13 15:40:00+01:00</th>\n",
       "      <td>1.105217</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-13 15:45:00+01:00</th>\n",
       "      <td>1.104972</td>\n",
       "      <td>-0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-13 15:50:00+01:00</th>\n",
       "      <td>1.104972</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-13 15:55:00+01:00</th>\n",
       "      <td>1.104972</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16940 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              price   returns\n",
       "Datetime                                     \n",
       "2023-01-20 00:05:00+00:00  1.084011  0.000433\n",
       "2023-01-20 00:10:00+00:00  1.084246  0.000217\n",
       "2023-01-20 00:15:00+00:00  1.084246  0.000000\n",
       "2023-01-20 00:20:00+00:00  1.084246  0.000000\n",
       "2023-01-20 00:25:00+00:00  1.084011 -0.000217\n",
       "...                             ...       ...\n",
       "2023-04-13 15:35:00+01:00  1.105217 -0.000774\n",
       "2023-04-13 15:40:00+01:00  1.105217  0.000000\n",
       "2023-04-13 15:45:00+01:00  1.104972 -0.000221\n",
       "2023-04-13 15:50:00+01:00  1.104972  0.000000\n",
       "2023-04-13 15:55:00+01:00  1.104972  0.000000\n",
       "\n",
       "[16940 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.991937, 0.961882)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.test_strategy(train_ratio = 0.7, lags = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been stored.\n"
     ]
    }
   ],
   "source": [
    "ml.store_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuantConnect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
